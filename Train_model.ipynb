{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2654,"status":"ok","timestamp":1632667341909,"user":{"displayName":"Long Nguyen Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZ09nXjU-7AnI9OnAWffCEIvC4ypg0U-POB1pVAg=s64","userId":"04250606013751201459"},"user_tz":-420},"id":"QW7omr_xjXRQ"},"outputs":[],"source":["import tensorflow as tf\n","import pathlib\n","from tensorflow import keras, lite\n","from tensorflow.keras.layers import Dense, Flatten\n","print(tf.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["IMG_SIZE = 96\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","BATCH_SIZE = 32\n","CLASSES = 4\n","EPOCHS = 10\n","LEARNING_RATE = 0.0034\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":347,"status":"ok","timestamp":1632667599931,"user":{"displayName":"Long Nguyen Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZ09nXjU-7AnI9OnAWffCEIvC4ypg0U-POB1pVAg=s64","userId":"04250606013751201459"},"user_tz":-420},"id":"S6CMUHjBj21x"},"outputs":[],"source":["data_dir = pathlib.Path('Dataset/Training')\n","test_dir = pathlib.Path('Dataset/Testing')\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","                                                                data_dir,\n","                                                                validation_split = 0.2,\n","                                                                subset = 'training',\n","                                                                seed = 123,\n","                                                                image_size = (IMG_SIZE,IMG_SIZE),\n","                                                                batch_size = BATCH_SIZE\n","                                                              )\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","                                                            data_dir,\n","                                                            validation_split = 0.2,\n","                                                            subset = 'validation',\n","                                                            seed = 123,\n","                                                            image_size = (IMG_SIZE,IMG_SIZE),\n","                                                            batch_size = BATCH_SIZE\n","                                                            )\n","test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","                                                            test_dir,\n","                                                            seed = 123,\n","                                                            image_size = (IMG_SIZE,IMG_SIZE),\n","                                                            batch_size = BATCH_SIZE\n","                                                            )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20, 3))\n","for images, labels in train_ds.take(1):\n","  for i in range(32):\n","    ax = plt.subplot(2, 16, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(train_ds.class_names[labels[i]])\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 7))\n","for images, labels in test_ds.take(1):\n","  for i in range(32):\n","    ax = plt.subplot(4, 8, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(test_ds.class_names[labels[i]])\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":858,"status":"ok","timestamp":1632668330880,"user":{"displayName":"Long Nguyen Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZ09nXjU-7AnI9OnAWffCEIvC4ypg0U-POB1pVAg=s64","userId":"04250606013751201459"},"user_tz":-420},"id":"ujd4gcszkvb6"},"outputs":[],"source":["from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","\n","\n","base_model = MobileNetV2(weights='imagenet',\n","                        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","                        # alpha=0.35,\n","                        include_top=False)\n","\n","base_model.trainable = False\n","\n","def model_maker():\n","  inputs = keras.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n","  x = preprocess_input(inputs)\n","  x = base_model(x, training=False)\n","  x = base_model.output\n","  flatten = Flatten()(x)\n","  outputs = Dense(CLASSES, activation='softmax')(flatten)\n","  model = keras.Model(base_model.input, outputs)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1632668625467,"user":{"displayName":"Long Nguyen Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZ09nXjU-7AnI9OnAWffCEIvC4ypg0U-POB1pVAg=s64","userId":"04250606013751201459"},"user_tz":-420},"id":"nWtB5ICSlE_m","outputId":"a3af548c-7252-4ff7-d308-5e917a7413d9"},"outputs":[],"source":["model = model_maker()\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from keras.utils.vis_utils import plot_model\n","# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":324,"status":"ok","timestamp":1632668630907,"user":{"displayName":"Long Nguyen Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZ09nXjU-7AnI9OnAWffCEIvC4ypg0U-POB1pVAg=s64","userId":"04250606013751201459"},"user_tz":-420},"id":"5OZnFjyglAv4"},"outputs":[],"source":["model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","               loss = 'sparse_categorical_crossentropy',\n","               metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":735412,"status":"ok","timestamp":1632669370030,"user":{"displayName":"Long Nguyen Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZ09nXjU-7AnI9OnAWffCEIvC4ypg0U-POB1pVAg=s64","userId":"04250606013751201459"},"user_tz":-420},"id":"rmxDH3iflcbX","outputId":"21bd141c-1d6e-483e-c079-4a6638473598"},"outputs":[],"source":["history = model.fit(train_ds,\n","                    validation_data = val_ds,\n","                    epochs = EPOCHS,\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(EPOCHS)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# import cv2\n","\n","# # multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n","\n","# #https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n","# face_cascade = cv2.CascadeClassifier('Haar/haarcascade_frontalface_default.xml')\n","# #https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n","# eye_cascade = cv2.CascadeClassifier('Haar/haarcascade_eye.xml')\n","\n","# # mouth_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n","\n","# cap = cv2.VideoCapture(0)\n","# while 1:\n","#     ret, img = cap.read()\n","#     img = cv2.flip(img, 1)\n","#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","#     faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n","\n","#     for (x,y,w,h) in faces:\n","#         roi_gray = gray[y:y+h, x:x+w]\n","#         roi_color = img[y:y+h, x:x+w]\n","#         roi_color = cv2.resize(roi_color, (96, 96))\n","#         eyes = eye_cascade.detectMultiScale(roi_gray)\n","#         for (ex,ey,ew,eh) in eyes:\n","#             cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n","#             img_array = tf.keras.utils.img_to_array(roi_color)\n","#             img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","#             predictions = model.predict(img_array)\n","#             score = tf.nn.softmax(predictions[0])\n","#             text = \"{} : {:.2f}\".format(classes[np.argmax(score)], 100 * np.max(score))\n","#             img = cv2.putText(img, text, (x,y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n","\n","\n","#     cv2.imshow('img',img)\n","#     k = cv2.waitKey(1) & 0xff\n","#     if k == 27:\n","#         break\n","\n","\n","# cv2.destroyAllWindows()\n","# cv2.waitKey(1)\n","# cap.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","class_names = test_ds.class_names\n","counter = [0] * len(class_names)\n","testing_path = \"Dataset5/Testing/\"\n","label = \"Wardah\"\n","\n","\n","label_path = os.path.join(testing_path, label)\n","\n","for image in os.listdir(label_path):\n","    image_path = os.path.join(label_path, image)\n","    try:\n","        img = tf.keras.utils.load_img(\n","            image_path, target_size=(96, 96)\n","        )\n","        img_array = tf.keras.utils.img_to_array(img)\n","        img_array = tf.expand_dims(img_array, 0) # Create a batch\n","        predictions = model.predict(img_array)\n","        score = tf.nn.softmax(predictions[0])\n","        print(\n","            \"{} : {:.2f} \\t\\t\\t {}\"\n","            .format(class_names[np.argmax(score)], 100 * np.max(score), image_path)\n","        )\n","        counter[np.argmax(score)] += 1\n","    except:\n","        print(\"Error loading image :\", image_path)\n","print(class_names)\n","print(counter)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","class_names = test_ds.class_names\n","img = tf.keras.utils.load_img(\n","    \"kanna.jpeg\", target_size=(96, 96)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","def representative_dataset():\n","  for data in tf.data.Dataset.from_tensor_slices((images)).batch(1).take(100):\n","    yield [tf.dtypes.cast(data, tf.float32)]\n","\n","# def representative_dataset():\n","#     for _ in range(100):\n","#       data = np.random.rand(1, 96, 96, 3)\n","#       yield [data.astype(np.float32)]\n","\n","# Convert the tflite.\n","converter = lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [lite.Optimize.DEFAULT]\n","converter.representative_dataset = representative_dataset\n","converter.target_spec.supported_ops = [lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.int8\n","converter.inference_output_type = tf.int8\n","tflite_quant_model = converter.convert()\n","\n","# Save the model.\n","with open('trained_01.tflite', 'wb') as f:\n","  f.write(tflite_quant_model)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPDcX6I4k2Zy6sH49qkwax5","collapsed_sections":[],"name":"Train_model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.10 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"vscode":{"interpreter":{"hash":"2f3b715b8572a86f23349f24abadf3718a00e4be38229103fe3c59b38106bc0c"}}},"nbformat":4,"nbformat_minor":0}
